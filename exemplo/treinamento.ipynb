{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# BASEADO EM: MARATONA BEHIND THE CODE\n",
    "\n",
    "## EXEMPLO DE USO NO KUBEFLOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em projetos de ciência de dados visando a construção de modelos de *machine learning*, ou aprendizado estatístico, é muito incomum que os dados iniciais estejam já no formato ideal para a construção de modelos. São necessários vários passos intermediários de pré-processamento de dados, como por exemplo a codificação de variáveis categóricas, normalização de variáveis numéricas, tratamento de dados faltantes, etc. A biblioteca **scikit-learn** -- uma das mais populares bibliotecas de código-aberto para *machine learning* no mundo -- possui diversas funções já integradas para a realização das transformações de dados mais utilizadas. Entretanto, em um fluxo comum de um modelo de aprendizado de máquina, é necessária a aplicação dessas transformações pelo menos duas vezes: a primeira vez para \"treinar\" o modelo, e depois novamente quando novos dados forem enviados como entrada para serem classificados por este modelo. \n",
    "\n",
    "Para facilitar o trabalho com esse tipo de fluxo, o scikit-learn possui também uma ferramenta chamada **Pipeline**, que nada mais é do que uma lista ordenada de transformações que devem ser aplicadas nos dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** ATENÇÃO **\n",
    "\n",
    "Este notebook serve apenas um propósito educativo, você pode alterar o código como quiser e nada aqui será avaliado/pontuado.\n",
    "\n",
    "A recomendação é que você experimente e teste diferentes algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabalhando com Pipelines do scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro, realizamos a instalação do scikit-learn versão 0.20.3, seaborn e do xgboost versão 0.71 no Kernel deste notebook\n",
    "!pip install scikit-learn==0.20.3 --upgrade\n",
    "!pip install seaborn --upgrade\n",
    "!pip install xgboost==0.71 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Em seguida iremos importar diversas bibliotecas que serão utilizadas:\n",
    "\n",
    "# Pacote para trabalhar com JSON\n",
    "import json\n",
    "\n",
    "# Pacote para realizar requisições HTTP\n",
    "import requests\n",
    "\n",
    "# Pacote para exploração e análise de dados\n",
    "import pandas as pd\n",
    "\n",
    "# Pacote com métodos numéricos e representações matriciais\n",
    "import numpy as np\n",
    "\n",
    "# Pacote para construção de modelo baseado na técnica Gradient Boosting\n",
    "import xgboost as xgb\n",
    "\n",
    "# Pacotes do scikit-learn para pré-processamento de dados\n",
    "# \"SimpleImputer\" é uma transformação para preencher valores faltantes em conjuntos de dados\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Pacotes do scikit-learn para treinamento de modelos e construção de pipelines\n",
    "# Método para separação de conjunto de dados em amostras de treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Método para criação de modelos baseados em árvores de decisão\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Classe para a criação de uma pipeline de machine-learning\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Pacotes do scikit-learn para avaliação de modelos\n",
    "# Métodos para validação cruzada do modelo criado\n",
    "from sklearn.model_selection import KFold, cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando um .csv para o Kernel deste notebook [ALTERADO FONTE DADOS: CURSO_DW.CSV]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro iremos importar o dataset fornecido para o desafio, que já está incluso neste projeto!\n",
    "\n",
    "Você pode realizar a importação dos dados de um arquivo .csv diretamente para o Kernel do notebook como um DataFrame da biblioteca Pandas, muito utilizada para a manipulação de dados em Python.\n",
    "\n",
    "Para realizar a importação, inserir o código necessário para importação e leitura dos dados no arquivo .csv como um DataFrame Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LE O DATASET COMO UM PANDAS DATAFRAME.\n",
    "df_data_1 = pd.read_csv('curso_dw.csv')\n",
    "\n",
    "df_data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 15 colunas presentes no dataset fornecido, sendo dezessete delas variáveis características (dados de entrada) e um delas uma variável-alvo (que queremos que o nosso modelo seja capaz de prever). \n",
    "\n",
    "As variáveis características são:\n",
    "\n",
    "    MATRICULA          - número de matrícula do estudante\n",
    "    NOME               - nome completo do estudante\n",
    "    REPROVACOES_MAT_1  - número de reprovações na disciplina\n",
    "    REPROVACOES_MAT_2  - número de reprovações na disciplina\n",
    "    REPROVACOES_MAT_3  - número de reprovações na disciplina\n",
    "    REPROVACOES_MAT_4  - número de reprovações na disciplina\n",
    "    NOTA_MAT_1         - média simples das notas do aluno na disciplina (0-10)\n",
    "    NOTA_MAT_2         - média simples das notas do aluno na disciplina (0-10)\n",
    "    NOTA_MAT_3         - média simples das notas do aluno na disciplina (0-10)\n",
    "    NOTA_MAT_4         - média simples das notas do aluno na disciplina (0-10)\n",
    "    INGLES             - indica se o estudante tem conhecimento em língua inglesa (0 -> sim ou 1 -> não)\n",
    "    H_AULA_PRES        - horas de estudo presencial realizadas pelo estudante\n",
    "    TAREFAS_ONLINE     - número de tarefas online entregues pelo estudante\n",
    "    FALTAS             - número de faltas acumuladas do estudante (todas disciplinas)\n",
    "    \n",
    "## NOVAS VARIÁVEIS são:\n",
    "    INGLES_DESC        - indica se o estudante tem conhecimento em língua inglesa (SIM, NÃO, SEM RESPOSTA)\n",
    "    CURSOU_MAT_1       - indica como o estudante foi na disciplina (APROVADO, REPROVADO, AINDA NAO CURSOU)\n",
    "    CURSOU_MAT_2       - indica como o estudante foi na disciplina (APROVADO, REPROVADO, AINDA NAO CURSOU)\n",
    "    CURSOU_MAT_3       - indica como o estudante foi na disciplina (APROVADO, REPROVADO, AINDA NAO CURSOU)\n",
    "    CURSOU_MAT_4       - indica como o estudante foi na disciplina (APROVADO, REPROVADO, AINDA NAO CURSOU)\n",
    "\n",
    "A variável-alvo é:\n",
    "\n",
    "    PERFIL               - uma *string* que indica uma de cinco possibilidades: \n",
    "        \"EXCELENTE\"      - Estudante não necessita de mentoria\n",
    "        \"MUITO BOM\"      - Estudante não necessita de mentoria\n",
    "        \"BOM\"            - Estudante não necessita de mentoria\n",
    "        \"REGULAR\"        - Estudante necessita de mentoria em algumas matérias\n",
    "        \"DIFICULDADE\"    - Estudante necessita de mentoria em várias disciplinas\n",
    "        \n",
    "Com um modelo capaz de classificar um estudante em uma dessas categorias, podemos automatizar parte da mentoria estudantil através de assistentes virtuais, que serão capazes de recomendar práticas de estudo e conteúdo personalizado com base nas necessidades de cada aluno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorando os dados fornecidos\n",
    "\n",
    "Podemos continuar a exploração dos dados fornecidos com a função ``info()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É notado que existem variáveis do tipo ``float64`` (números \"decimais\"), variáveis do tipo ``int64`` (números inteiros) e do tipo ``object`` (nesse caso são *strings*, ou texto). \n",
    "\n",
    "Como a maioria dos algoritmos de aprendizado estatístico supervisionado só aceita valores numéricos como entrada, é necessário então o pré-processamento das variáveis do tipo \"object\" antes de usar esse dataset como entrada para o treinamento de um modelo. Também é notado que existem valores faltantes em várias colunas. Esses valores faltantes também devem ser tratados antes de serem construídos modelos com esse conjunto de dados base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função ``describe()`` gera várias informações sobre as variáveis numéricas que também podem ser úteis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizações\n",
    "\n",
    "Para visualizar o dataset fornecido, podemos utilizar as bibliotecas ``matplotlib`` e ``seaborn``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline",
    "import warnings",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(28, 4))\n",
    "\n",
    "sns.countplot(ax=axes[0], x='REPROVACOES_MAT_1', data=df_data_1)\n",
    "sns.countplot(ax=axes[1], x='REPROVACOES_MAT_2', data=df_data_1)\n",
    "sns.countplot(ax=axes[2], x='REPROVACOES_MAT_3', data=df_data_1)\n",
    "sns.countplot(ax=axes[3], x='REPROVACOES_MAT_4', data=df_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(28, 4))\n",
    "\n",
    "sns.histplot(df_data_1['NOTA_MAT_1'], ax=axes[0])\n",
    "sns.histplot(df_data_1['NOTA_MAT_2'], ax=axes[1])\n",
    "sns.histplot(df_data_1['NOTA_MAT_3'], ax=axes[2])\n",
    "sns.histplot(df_data_1['NOTA_MAT_4'].dropna(), ax=axes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(28, 4))\n",
    "\n",
    "sns.countplot(ax=axes[0], x='INGLES', data=df_data_1)\n",
    "sns.countplot(ax=axes[1], x='FALTAS', data=df_data_1)\n",
    "sns.countplot(ax=axes[2], x='H_AULA_PRES', data=df_data_1)\n",
    "sns.countplot(ax=axes[3], x='TAREFAS_ONLINE', data=df_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.plot()\n",
    "sns.countplot(x='PERFIL', data=df_data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** ATENÇÃO **\n",
    "\n",
    "Você pode notar pela figura acima que este dataset é desbalanceado, isto é, a quantidade de amostras para cada classe que desejamos classificar é bem discrepante. O participante é livre para adicionar ou remover **LINHAS** no dataset fornecido, inclusive utilizar bibliotecas para balanceamento com ``imblearn``. Entretanto tome **muito cuidado**!!! Você não pode alterar os tipos dos dados e nem remover ou desordenar o dataset fornecido. Todas as operações desse tipo deverão ser feitas por meio de Transforms do scikit-learn :)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizando o pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o pré-processamento dos dados serão apresentadas duas transformações básicas neste notebook, demonstrando a construção de uma Pipeline com um modelo funcional. Esta Pipeline funcional fornecida deverá ser melhorada pelo participante para que o modelo final alcance a maior acurácia possível, garantindo uma pontuação maior no desafio. Essa melhoria pode ser feita apenas no pré-processamento dos dados, na escolha de um algoritmo para treinamento de modelo diferente, ou até mesmo na alteração do *framework* usado (*scikit-learn*).\n",
    "\n",
    "A primeira transformação (passo na nossa Pipeline) será a exclusão da coluna \"NOME\" do nosso dataset, que além de não ser uma variável numérica, também não é uma variável relacionada ao desempenho dos estudantes nas disciplinas. Existem funções prontas no scikit-learn para a realização dessa transformação, entretanto nosso exemplo irá demonstrar como criar uma transformação personalizada do zero no scikit-learn. Se desejado, o participante poderá utilizar esse exemplo para criar outras transformações e adicioná-las à Pipeline final :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformação 1: excluindo colunas do dataset\n",
    "\n",
    "Para a criação de uma transformação de dados personalizada no scikit-learn, é necessária basicamente a criação de uma classe com os métodos ``transform`` e ``fit``. No método transform será executada a lógica da nossa transformação.\n",
    "\n",
    "Na próxima célula é apresentado o código completo de uma transformação ``DropColumns`` para a remoção de colunas de um DataFrame pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "# All sklearn Transforms must have the `transform` and `fit` methods\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Primeiro realizamos a cópia do dataframe 'X' de entrada\n",
    "        data = X.copy()\n",
    "        # Retornamos um novo dataframe sem as colunas indesejadas\n",
    "        return data.drop(labels=self.columns, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aplicar essa transformação em um DataFrame pandas, basta instanciar um objeto *DropColumns* e chamar o método transform()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando uma transformação DropColumns\n",
    "rm_columns = DropColumns(\n",
    "    columns=[\"NOME\"]  # Essa transformação recebe como parâmetro uma lista com os nomes das colunas indesejadas\n",
    ")\n",
    "\n",
    "print(rm_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando as colunas do dataset original\n",
    "print(\"Colunas do dataset original: \\n\")\n",
    "print(df_data_1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a transformação ``DropColumns`` ao conjunto de dados base\n",
    "rm_columns.fit(X=df_data_1)\n",
    "\n",
    "# Reconstruindo um DataFrame Pandas com o resultado da transformação\n",
    "df_data_2 = pd.DataFrame.from_records(\n",
    "    data=rm_columns.transform(\n",
    "        X=df_data_1\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando as colunas do dataset transformado\n",
    "print(\"Colunas do dataset após a transformação ``DropColumns``: \\n\")\n",
    "print(df_data_2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se que a coluna \"NOME\" foi removida e nosso dataset agora poossui apenas 17 colunas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformação 2: tratando dados faltantes\n",
    "\n",
    "Para tratar os dados faltantes em nosso conjunto de dados, iremos agora utilizar uma transformação pronta da biblioteca scikit-learn, chamada **SimpleImputer**.\n",
    "\n",
    "Essa transformação permite diversas estratégias para o tratamento de dados faltantes. A documentação oficial pode ser encontrada em: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "\n",
    "Neste exemplo iremos simplesmente transformar todos os valores faltantes em zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de um objeto ``SimpleImputer``\n",
    "si = SimpleImputer(\n",
    "    missing_values=np.nan,  # os valores faltantes são do tipo ``np.nan`` (padrão Pandas)\n",
    "    strategy='constant',  # a estratégia escolhida é a alteração do valor faltante por uma constante\n",
    "    fill_value=0,  # a constante que será usada para preenchimento dos valores faltantes é um int64=0.\n",
    "    #verbose=0,\n",
    "    copy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os dados faltantes do dataset após a primeira transformação (df_data_2)\n",
    "print(\"Valores nulos antes da transformação SimpleImputer: \\n\\n{}\\n\".format(df_data_2.isnull().sum(axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos o SimpleImputer ``si`` ao conjunto de dados df_data_2 (resultado da primeira transformação)\n",
    "si.fit(X=df_data_2)\n",
    "\n",
    "# Reconstrução de um novo DataFrame Pandas com o conjunto imputado (df_data_3)\n",
    "df_data_3 = pd.DataFrame.from_records(\n",
    "    data=si.transform(\n",
    "        X=df_data_2\n",
    "    ),  # o resultado SimpleImputer.transform(<<pandas dataframe>>) é lista de listas\n",
    "    columns=df_data_2.columns  # as colunas originais devem ser conservadas nessa transformação\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os dados faltantes do dataset após a segunda transformação (SimpleImputer) (df_data_3)\n",
    "print(\"Valores nulos no dataset após a transformação SimpleImputer: \\n\\n{}\\n\".format(df_data_3.isnull().sum(axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se que não temos mais nenhum valor faltante no nosso conjunto de dados :)\n",
    "\n",
    "Vale salientar que nem sempre a alteração dos valores faltantes por 0 é a melhor estratégia. O participante é incentivado a estudar e implementar estratégias diferentes de tratamento dos valores faltantes para aprimorar seu modelo e melhorar sua pontuação final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando um modelo de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalizado o pré-processamento, já temos o conjunto de dados no formato necessário para o treinamento do nosso modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo fornecido, iremos utilizar todas as colunas, exceto a coluna **LABELS** como *features* (variáveis de entrada).\n",
    "\n",
    "A variável **LABELS** será a variável-alvo do modelo, conforme descrito no enunciado do desafio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definindo as features do modelo [ALTERADO PARA UTILIZAR AS NOVAS COLUNAS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformar_dados : novas colunas para uso no ML\n",
    "\n",
    "df = df_data_3\n",
    "\n",
    "# 3) inserir coluna descritiva sobre os alunos que falam ingles, ajustando valores nulos\n",
    "import numpy as np\n",
    "df[\"INGLES\"].fillna(-1, inplace = True)\n",
    "\n",
    "#conditions = [df['INGLES'] > 0, df['INGLES'] == 0, df['INGLES'] < 0]\n",
    "#choices = ['SIM', 'NÃO', 'SEM RESPOSTA'] # COLUNA COM NOVOS VALORES CRIADOS NESSA ETAPA\n",
    "#df['INGLES_DESC'] = np.select(conditions, choices)\n",
    "\n",
    "# 4) eliminar nota ZERO de alunos sem reprovação (ainda não cursaram as matérias 1, 2, 3, 4)\n",
    "# APROVADO, NOTA >= 4\n",
    "cond1_mat1 = (df['NOTA_MAT_1'] >= 4) & (df['REPROVACOES_MAT_1'] == 0)\n",
    "cond1_mat2 = (df['NOTA_MAT_2'] >= 4) & (df['REPROVACOES_MAT_2'] == 0)\n",
    "cond1_mat3 = (df['NOTA_MAT_3'] >= 4) & (df['REPROVACOES_MAT_3'] == 0)\n",
    "cond1_mat4 = (df['NOTA_MAT_4'] >= 4) & (df['REPROVACOES_MAT_4'] == 0)\n",
    "# REPROVADO, NOTA < 4\n",
    "cond2_mat1 = (df['NOTA_MAT_1'] < 4) & (df['REPROVACOES_MAT_1'] > 0)\n",
    "cond2_mat2 = (df['NOTA_MAT_2'] < 4) & (df['REPROVACOES_MAT_2'] > 0)\n",
    "cond2_mat3 = (df['NOTA_MAT_3'] < 4) & (df['REPROVACOES_MAT_3'] > 0)\n",
    "cond2_mat4 = (df['NOTA_MAT_4'] < 4) & (df['REPROVACOES_MAT_4'] > 0)\n",
    "# AINDA NAO CURSOU : NOTA = 0, SEM REPROVAÇÕES\n",
    "cond3_mat1 = (df['NOTA_MAT_1'] == 0) & (df['REPROVACOES_MAT_1'] == 0)\n",
    "cond3_mat2 = (df['NOTA_MAT_2'] == 0) & (df['REPROVACOES_MAT_2'] == 0)\n",
    "cond3_mat3 = (df['NOTA_MAT_3'] == 0) & (df['REPROVACOES_MAT_3'] == 0)\n",
    "cond3_mat4 = (df['NOTA_MAT_4'] == 0) & (df['REPROVACOES_MAT_4'] == 0)\n",
    "# CONDICOES:\n",
    "conditions_MAT1 = [cond1_mat1, cond2_mat1, cond3_mat1]\n",
    "conditions_MAT2 = [cond1_mat2, cond2_mat2, cond3_mat2]\n",
    "conditions_MAT3 = [cond1_mat3, cond2_mat3, cond3_mat3]\n",
    "conditions_MAT4 = [cond1_mat4, cond2_mat4, cond3_mat4]\n",
    "\n",
    "choices = [1, 0, -1] # COLUNA COM NOVOS VALORES CRIADOS NESSA ETAPA\n",
    "#choices = ['APROVADO', 'REPROVADO', 'AINDA NAO CURSOU'] # COLUNA COM NOVOS VALORES CRIADOS NESSA ETAPA\n",
    "# CRIANDO NOVAS COLUNAS:\n",
    "df['CURSOU_MAT1_DESC'] = np.select(conditions_MAT1, choices)\n",
    "df['CURSOU_MAT2_DESC'] = np.select(conditions_MAT2, choices)\n",
    "df['CURSOU_MAT3_DESC'] = np.select(conditions_MAT3, choices)\n",
    "df['CURSOU_MAT4_DESC'] = np.select(conditions_MAT4, choices)\n",
    "\n",
    "# Definir nota media na materia, caso nao tenha cursado\n",
    "\n",
    "print(df.NOTA_MAT_1.mean())\n",
    "print(df.NOTA_MAT_2.mean())\n",
    "print(df.NOTA_MAT_3.mean())\n",
    "print(df.NOTA_MAT_4.mean())\n",
    "\n",
    "\n",
    "# Se 'AINDA NAO CURSOU': recebe a nota média para evitar interferencia nos dados\n",
    "MEDIA_NOTA_MAT_1 = df.loc[df.CURSOU_MAT1_DESC != -1, 'NOTA_MAT_1'].mean()\n",
    "MEDIA_NOTA_MAT_2 = df.loc[df.CURSOU_MAT2_DESC != -1, 'NOTA_MAT_2'].mean()\n",
    "MEDIA_NOTA_MAT_3 = df.loc[df.CURSOU_MAT3_DESC != -1, 'NOTA_MAT_3'].mean()\n",
    "MEDIA_NOTA_MAT_4 = df.loc[df.CURSOU_MAT4_DESC != -1, 'NOTA_MAT_4'].mean()\n",
    "\n",
    "print(\"\\n\\ncheck\\n\\n\")\n",
    "\n",
    "# calcula media 'NOTA_MAT' dos aprovados e reprovado\n",
    "df.loc[df['CURSOU_MAT1_DESC'] == -1, 'NOTA_MAT_1'] = MEDIA_NOTA_MAT_1\n",
    "df.loc[df['CURSOU_MAT2_DESC'] == -1, 'NOTA_MAT_2'] = MEDIA_NOTA_MAT_2\n",
    "df.loc[df['CURSOU_MAT3_DESC'] == -1, 'NOTA_MAT_3'] = MEDIA_NOTA_MAT_3\n",
    "df.loc[df['CURSOU_MAT4_DESC'] == -1, 'NOTA_MAT_4'] = MEDIA_NOTA_MAT_4\n",
    "\n",
    "print(df.NOTA_MAT_1.mean())\n",
    "print(df.NOTA_MAT_2.mean())\n",
    "print(df.NOTA_MAT_3.mean())\n",
    "print(df.NOTA_MAT_4.mean())\n",
    "\n",
    "df_data_4 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das colunas que serão features (nota-se que a coluna NOME não está presente)\n",
    "features = [\n",
    "    \"MATRICULA\", 'REPROVACOES_MAT_1', 'REPROVACOES_MAT_2', \"REPROVACOES_MAT_3\", \"REPROVACOES_MAT_4\",\n",
    "    \"NOTA_MAT_1\", \"NOTA_MAT_2\", \"NOTA_MAT_3\", \"NOTA_MAT_4\",\n",
    "    \"INGLES\", \"H_AULA_PRES\", \"TAREFAS_ONLINE\", \"FALTAS\", \n",
    "    #\"INGLES_DESC\", # somente valores numeros serao usados\n",
    "    \"CURSOU_MAT1_DESC\", \"CURSOU_MAT2_DESC\", \"CURSOU_MAT3_DESC\", \"CURSOU_MAT4_DESC\",\n",
    "]\n",
    "\n",
    "# Definição da variável-alvo\n",
    "target = [\"PERFIL\"]\n",
    "\n",
    "# Preparação dos argumentos para os métodos da biblioteca ``scikit-learn``\n",
    "X = df_data_4[features]\n",
    "y = df_data_4[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de entrada (X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As variáveis-alvo correspondentes (y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando o dataset em um conjunto de treino e um conjunto de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos separar o dataset fornecido em dois grupos: um para treinar nosso modelo, e outro para testarmos o resultado através de um teste cego. A separação do dataset pode ser feita facilmente com o método *train_test_split()* do scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados em um conjunto de treino e um conjunto de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando um modelo baseado em árvores de decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo fornecido iremos criar um classificador baseado em **árvores de decisão**.\n",
    "\n",
    "Material teórico sobre árvores de decisão na documentação oficial do scikit-learn: https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "O primeiro passo é basicamente instanciar um objeto *DecisionTreeClassifier()* da biblioteca scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de uma árvore de decisão com a biblioteca ``scikit-learn``:\n",
    "decision_tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando o classificador baseado em árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino do modelo (é chamado o método *fit()* com os conjuntos de treino)\n",
    "decision_tree.fit(\n",
    "    X_train,\n",
    "    y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execução de predições e avaliação da árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realização de teste cego no modelo criado\n",
    "y_pred = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Acurácia alcançada pela árvore de decisão\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste notebook foi demonstrado como trabalhar com transformações e modelos com a biblioteca scikit-learn. É recomendado que o participante realize seus experimentos editando o código fornecido aqui até que um modelo com acurácia elevada seja alcançado.\n",
    "\n",
    "Quando você estiver satisfeito com seu modelo, pode passar para a segunda etapa do desafio -- encapsular seu modelo como uma API REST !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporta o modelo matemático gerado para um arquivo:\n",
    "!pip install joblib --upgrade\n",
    "from joblib import dump\n",
    "dump(decision_tree, 'model.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
