{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d57e4d8-9d73-445d-bc9c-0940abcbd74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /usr/local/lib/python3.8/dist-packages (2.17.2)\n",
      "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.8/dist-packages (from mlflow) (3.0.3)\n",
      "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.8/dist-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.8/dist-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: mlflow-skinny==2.17.2 in /usr/local/lib/python3.8/dist-packages (from mlflow) (2.17.2)\n",
      "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.9.1)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.8/dist-packages (from mlflow) (3.6.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.8/dist-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.14.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow) (2.0.40)\n",
      "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.8/dist-packages (from mlflow) (0.24.2)\n",
      "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.5.0)\n",
      "Requirement already satisfied: pyarrow<18,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from mlflow) (9.0.0)\n",
      "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.23.3)\n",
      "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.8/dist-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from mlflow-skinny==2.17.2->mlflow) (1.32.1)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow-skinny==2.17.2->mlflow) (0.5.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.8/dist-packages (from mlflow-skinny==2.17.2->mlflow) (6.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.8/dist-packages (from mlflow-skinny==2.17.2->mlflow) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from mlflow-skinny==2.17.2->mlflow) (8.5.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from mlflow-skinny==2.17.2->mlflow) (5.5.2)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.8/dist-packages (from mlflow-skinny==2.17.2->mlflow) (3.1.44)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from mlflow-skinny==2.17.2->mlflow) (5.29.4)\n",
      "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.8/dist-packages (from mlflow-skinny==2.17.2->mlflow) (2.2.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from mlflow-skinny==2.17.2->mlflow) (1.32.1)\n",
      "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.8/dist-packages (from mlflow-skinny==2.17.2->mlflow) (21.3)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.8/dist-packages (from mlflow-skinny==2.17.2->mlflow) (2.28.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from mlflow-skinny==2.17.2->mlflow) (0.50.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.8/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.13.2)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.8/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic!=1.10.0,<2->mlflow) (5.9.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.8/dist-packages (from docker<8,>=4.0.0->mlflow) (1.26.12)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from Flask<4->mlflow) (3.0.6)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.8/dist-packages (from Flask<4->mlflow) (1.8.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.8/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.8/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.8/dist-packages (from graphene<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.8/dist-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow) (4.37.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow) (1.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas<3->mlflow) (2022.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<2->mlflow) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<2->mlflow) (1.2.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.8/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (2.39.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.2->mlflow) (4.0.12)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.2->mlflow) (3.20.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.8/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow) (1.2.18)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /usr/local/lib/python3.8/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow) (0.53b1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.2->mlflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.2->mlflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.2->mlflow) (2022.9.14)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.8/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow) (1.17.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.2->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (4.9.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (0.6.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip3.8'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='25.0.1'),)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.67.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip3.8'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='25.0.1'),)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pprint (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pprint\u001b[0m\u001b[31m\n",
      "\u001b[0m--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip3.8'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='25.0.1'),)\n"
     ]
    }
   ],
   "source": [
    "# Primeiro, realizamos a instalação do mlflow e autoML do sklearn\n",
    "\n",
    "#!pip install auto-sklearn\n",
    "\n",
    "!pip install mlflow\n",
    "\n",
    "!pip install tqdm \n",
    "\n",
    "!pip install pprint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513cb682-1125-4b87-ad28-f1e66c5cd728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://44.220.243.252:8089\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import requests\n",
    "\n",
    "url = \"http://checkip.amazonaws.com\"\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "    IP = response.text.replace('\\n', '')\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "uri_mlflow = \"http://\"+IP+\":8089\"\n",
    "print(uri_mlflow)\n",
    "\n",
    "mlflow.set_tracking_uri(uri_mlflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b7dee4-9ebd-4141-9e77-e2810c10f325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# LE O DATASET COMO UM PANDAS DATAFRAME.\n",
    "df_data = pd.read_csv('curso_dw.csv')\n",
    "\n",
    "# Definição das colunas que serão features (nota-se que a coluna NOME não está presente)\n",
    "features = [\n",
    "    #\"MATRICULA\",\n",
    "    \"REPROVACOES_MAT_1\", 'REPROVACOES_MAT_2', \"REPROVACOES_MAT_3\", \"REPROVACOES_MAT_4\",\n",
    "    \"NOTA_MAT_1\", \"NOTA_MAT_2\", \"NOTA_MAT_3\", \"NOTA_MAT_4\",\n",
    "    \"INGLES\", \"H_AULA_PRES\", \"TAREFAS_ONLINE\", \"FALTAS\", \n",
    "    #\"INGLES_DESC\", # usando todas as colunas\n",
    "    #\"CURSOU_MAT1_DESC\", \"CURSOU_MAT2_DESC\", \"CURSOU_MAT3_DESC\", \"CURSOU_MAT4_DESC\",\n",
    "]\n",
    "\n",
    "# Definição da variável-alvo\n",
    "target = [\"PERFIL\"]\n",
    "\n",
    "# Preparação dos argumentos para os métodos da biblioteca ``scikit-learn``\n",
    "X = df_data[features]\n",
    "y = df_data[target]\n",
    "\n",
    "# Separação dos dados em um conjunto de treino e um conjunto de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a568842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoML training progress: 100%|███████████████████████████████████| 300/300 [05:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Ranking dos modelos testados: \n",
      "\n",
      "          rank  ensemble_weight               type      cost   duration\n",
      "model_id                                                               \n",
      "5            1             0.24      random_forest  0.193344   8.359419\n",
      "9            2             0.18  gradient_boosting  0.194219   9.839831\n",
      "26           3             0.02                mlp  0.200350  21.292783\n",
      "4            4             0.02  gradient_boosting  0.218524   7.771238\n",
      "21           5             0.02      liblinear_svc  0.219838   2.675278\n",
      "33           6             0.02                mlp  0.220276   7.070588\n",
      "16           7             0.04                lda  0.228596  14.865296\n",
      "23           8             0.04      random_forest  0.237355  22.436863\n",
      "24           9             0.38                lda  0.238012   2.294205\n",
      "25          10             0.04                lda  0.241077   1.628145\n",
      "\\Acurácia: 0.8102\n"
     ]
    }
   ],
   "source": [
    "import autosklearn.classification\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "# Parâmetros do AutoML\n",
    "total_time = 300  # Tempo total (em segundos)\n",
    "per_model_time = 30  # Tempo máximo por modelo\n",
    "\n",
    "# Criando uma barra de progresso em thread separada\n",
    "def show_progress_bar(duration):\n",
    "    for _ in tqdm(range(duration), desc=\"AutoML training progress\", ncols=100):\n",
    "        time.sleep(1)\n",
    "\n",
    "# Iniciando barra de progresso em segundo plano\n",
    "progress_thread = threading.Thread(target=show_progress_bar, args=(total_time,))\n",
    "progress_thread.start()\n",
    "\n",
    "# Treinamento com auto-sklearn\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=total_time,\n",
    "    per_run_time_limit=per_model_time,\n",
    "    tmp_folder='/tmp/autosklearn_tmp',\n",
    "    #output_folder='/tmp/autosklearn_out',\n",
    "    disable_evaluator_output=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "# Espera barra terminar se for mais rápida\n",
    "progress_thread.join()\n",
    "\n",
    "# Resultados\n",
    "print(\"\\Ranking dos modelos testados: \\n\")\n",
    "print(automl.leaderboard())\n",
    "\n",
    "y_pred = automl.predict(X_test)\n",
    "print(f\"\\Acurácia: {accuracy_score(y_test, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b9ac07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelos testados: \n",
      "\n",
      "{   4: {   'balancing': Balancing(random_state=1),\n",
      "           'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff6e297a5e0>,\n",
      "           'cost': 0.21852419531421063,\n",
      "           'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff6f924a4c0>,\n",
      "           'ensemble_weight': 0.02,\n",
      "           'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff6e297a430>,\n",
      "           'model_id': 4,\n",
      "           'rank': 1,\n",
      "           'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
      "                               l2_regularization=1.3153561911035717e-10,\n",
      "                               learning_rate=0.025345400213312417, max_iter=256,\n",
      "                               max_leaf_nodes=16, min_samples_leaf=27,\n",
      "                               n_iter_no_change=5, random_state=1,\n",
      "                               validation_fraction=0.2361478213622299,\n",
      "                               warm_start=True)},\n",
      "    5: {   'balancing': Balancing(random_state=1),\n",
      "           'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff6e29a8e20>,\n",
      "           'cost': 0.19334355156557914,\n",
      "           'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff6e34a1670>,\n",
      "           'ensemble_weight': 0.24,\n",
      "           'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff6e29a8af0>,\n",
      "           'model_id': 5,\n",
      "           'rank': 2,\n",
      "           'sklearn_classifier': RandomForestClassifier(max_features=1, min_samples_split=3, n_estimators=512,\n",
      "                       n_jobs=1, random_state=1, warm_start=True)},\n",
      "    9: {   'balancing': Balancing(random_state=1),\n",
      "           'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff6e2b54b50>,\n",
      "           'cost': 0.19421940004379246,\n",
      "           'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff6e30fdb20>,\n",
      "           'ensemble_weight': 0.18,\n",
      "           'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff6e2b54190>,\n",
      "           'model_id': 9,\n",
      "           'rank': 3,\n",
      "           'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
      "                               l2_regularization=9.674948183980905e-09,\n",
      "                               learning_rate=0.014247987845444413, max_iter=256,\n",
      "                               max_leaf_nodes=55, min_samples_leaf=164,\n",
      "                               n_iter_no_change=1, random_state=1,\n",
      "                               validation_fraction=0.11770489601182355,\n",
      "                               warm_start=True)},\n",
      "    16: {   'balancing': Balancing(random_state=1),\n",
      "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff6de5487f0>,\n",
      "            'cost': 0.22859645281366325,\n",
      "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff6e2c838b0>,\n",
      "            'ensemble_weight': 0.04,\n",
      "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff6de548640>,\n",
      "            'model_id': 16,\n",
      "            'rank': 4,\n",
      "            'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
      "                           tol=0.018821286956948503)},\n",
      "    21: {   'balancing': Balancing(random_state=1, strategy='weighting'),\n",
      "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff6de464820>,\n",
      "            'cost': 0.21983796803153055,\n",
      "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff6de5272e0>,\n",
      "            'ensemble_weight': 0.02,\n",
      "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff6de4646a0>,\n",
      "            'model_id': 21,\n",
      "            'rank': 5,\n",
      "            'sklearn_classifier': LinearSVC(C=999.897948630207, class_weight='balanced', dual=False,\n",
      "          intercept_scaling=1.0, random_state=1, tol=7.067903490334549e-05)},\n",
      "    23: {   'balancing': Balancing(random_state=1),\n",
      "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff6dc922d60>,\n",
      "            'cost': 0.23735493759579596,\n",
      "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff6de527e80>,\n",
      "            'ensemble_weight': 0.04,\n",
      "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff6dc922ca0>,\n",
      "            'model_id': 23,\n",
      "            'rank': 6,\n",
      "            'sklearn_classifier': RandomForestClassifier(max_features=8, min_samples_leaf=9, min_samples_split=16,\n",
      "                       n_estimators=512, n_jobs=1, random_state=1,\n",
      "                       warm_start=True)},\n",
      "    24: {   'balancing': Balancing(random_state=1, strategy='weighting'),\n",
      "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff6e292c0d0>,\n",
      "            'cost': 0.23801182395445586,\n",
      "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff6de497d90>,\n",
      "            'ensemble_weight': 0.38,\n",
      "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff6e2899eb0>,\n",
      "            'model_id': 24,\n",
      "            'rank': 7,\n",
      "            'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage=0.3306135150299744, solver='lsqr',\n",
      "                           tol=0.0007215763283486354)},\n",
      "    25: {   'balancing': Balancing(random_state=1, strategy='weighting'),\n",
      "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff6f83a8940>,\n",
      "            'cost': 0.2410772936282023,\n",
      "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff6de48b610>,\n",
      "            'ensemble_weight': 0.04,\n",
      "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff6e3060550>,\n",
      "            'model_id': 25,\n",
      "            'rank': 8,\n",
      "            'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
      "                           tol=0.00010000000000000009)},\n",
      "    26: {   'balancing': Balancing(random_state=1),\n",
      "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff6f935f670>,\n",
      "            'cost': 0.20035033939128533,\n",
      "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff6dc882df0>,\n",
      "            'ensemble_weight': 0.02,\n",
      "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff6f935f4c0>,\n",
      "            'model_id': 26,\n",
      "            'rank': 9,\n",
      "            'sklearn_classifier': MLPClassifier(activation='tanh', alpha=0.00012344934870642978, beta_1=0.999,\n",
      "              beta_2=0.9, hidden_layer_sizes=(32,),\n",
      "              learning_rate_init=0.0010302058554176633, max_iter=256,\n",
      "              n_iter_no_change=32, random_state=1, validation_fraction=0.0,\n",
      "              verbose=0, warm_start=True)},\n",
      "    33: {   'balancing': Balancing(random_state=1),\n",
      "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff6f945b8e0>,\n",
      "            'cost': 0.22027589227063715,\n",
      "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff6e2bfd460>,\n",
      "            'ensemble_weight': 0.02,\n",
      "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff6f943cdf0>,\n",
      "            'model_id': 33,\n",
      "            'rank': 10,\n",
      "            'sklearn_classifier': MLPClassifier(activation='tanh', alpha=0.028065727598830293, beta_1=0.999,\n",
      "              beta_2=0.9, hidden_layer_sizes=(58, 58),\n",
      "              learning_rate_init=0.0004793055717891526, max_iter=64,\n",
      "              n_iter_no_change=32, random_state=1, validation_fraction=0.0,\n",
      "              verbose=0, warm_start=True)}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "# Resultados\n",
    "print(\"\\nModelos testados: \\n\")\n",
    "\n",
    "pp.pprint(automl.show_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f6022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Sample DataFrame : Exemplo com 3 formas geometricas com diferentes tamanhos e cores\n",
    "data = { 'Shape': ['Circle', 'Square', 'Triangle', 'Circle'],\n",
    "        'Color': ['Red', 'Blue', 'Green', 'Red'], \n",
    "        'Size': ['Small', 'Medium', 'Large', 'Small']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Sample DataFrame:\\n\", df)\n",
    "\n",
    "# Using LabelEncoder (sklearn)\n",
    "df_le = pd.DataFrame()\n",
    "le = LabelEncoder()\n",
    "for col in df.columns:\n",
    "    df_le[col + '_le'] = le.fit_transform(df[col])\n",
    "\n",
    "print(\"\\nLabelEncoder DataFrame:\\n\", df_le)\n",
    "\n",
    "\n",
    "# Using get_dummies to encode multiple columns\n",
    "df_encoded_multiple = pd.get_dummies(df, columns=['Color', 'Size', 'Shape'])\n",
    "print(\"\\nPandas get_dummies Encoded colunas:\\n\", df_encoded_multiple)\n",
    "\n",
    "# Dropping the first dummy column to avoid multicollinearity\n",
    "df_encoded_drop_first = pd.get_dummies(df, columns=['Color'], drop_first=True)\n",
    "print(\"\\nEncoded with drop_first column to avoid multicollinearity:\\n\", df_encoded_drop_first)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a27b5864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LabelEncoder DataFrame: \n",
      "\n",
      "    MATRICULA                       NOME  REPROVACOES_MAT_1  REPROVACOES_MAT_2  \\\n",
      "0     502375          Márcia Illiglener                  0                  0   \n",
      "1     397093   Jason Jytereoman Izoimum                  0                  0   \n",
      "2     915288  Bartolomeu Inácio da Gama                  0                  0   \n",
      "3     192652            Fernanda Guedes                  1                  3   \n",
      "4     949491     Alessandre Borba Gomes                  1                  3   \n",
      "\n",
      "   REPROVACOES_MAT_3  REPROVACOES_MAT_4  NOTA_MAT_1  NOTA_MAT_2  NOTA_MAT_3  \\\n",
      "0                  0                  0         6.2         5.8         4.6   \n",
      "1                  0                  0         6.0         6.2         5.2   \n",
      "2                  0                  0         7.3         6.7         7.1   \n",
      "3                  1                  1         0.0         0.0         0.0   \n",
      "4                  1                  1         0.0         0.0         0.0   \n",
      "\n",
      "   NOTA_MAT_4  INGLES  H_AULA_PRES  TAREFAS_ONLINE  FALTAS  PERFIL  \\\n",
      "0         5.9     0.0            2               4       3       4   \n",
      "1         4.5     1.0            2               4       3       4   \n",
      "2         7.2     0.0            5               0       3       0   \n",
      "3         0.0     1.0            4               4       4       1   \n",
      "4         0.0     1.0            5               2       5       1   \n",
      "\n",
      "   INGLES_DESC  CURSOU_MAT1_DESC  CURSOU_MAT2_DESC  CURSOU_MAT3_DESC  \\\n",
      "0            0                 1                 1                 1   \n",
      "1            2                 1                 1                 1   \n",
      "2            0                 1                 1                 1   \n",
      "3            2                 2                 2                 2   \n",
      "4            2                 2                 2                 2   \n",
      "\n",
      "   CURSOU_MAT4_DESC  \n",
      "0                 1  \n",
      "1                 1  \n",
      "2                 1  \n",
      "3                 2  \n",
      "4                 2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# LE O DATASET COMO UM PANDAS DATAFRAME.\n",
    "df_numeros = pd.read_csv('curso_dw.csv')\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "df_numeros['INGLES_DESC'] = le.fit_transform(df_numeros['INGLES_DESC'])\n",
    "df_numeros['CURSOU_MAT1_DESC'] = le.fit_transform(df_numeros['CURSOU_MAT1_DESC'])\n",
    "df_numeros['CURSOU_MAT2_DESC'] = le.fit_transform(df_numeros['CURSOU_MAT2_DESC'])\n",
    "df_numeros['CURSOU_MAT3_DESC'] = le.fit_transform(df_numeros['CURSOU_MAT3_DESC'])\n",
    "df_numeros['CURSOU_MAT4_DESC'] = le.fit_transform(df_numeros['CURSOU_MAT4_DESC'])\n",
    "df_numeros['PERFIL'] = le.fit_transform(df_numeros['PERFIL'])\n",
    "\n",
    "\n",
    "print(\"\\nLabelEncoder DataFrame: \\n\\n\", df_numeros.head())\n",
    "\n",
    "# Definição das colunas que serão features (nota-se que a coluna NOME não está presente)\n",
    "features = [\n",
    "    #\"MATRICULA\",\n",
    "    \"REPROVACOES_MAT_1\", 'REPROVACOES_MAT_2', \"REPROVACOES_MAT_3\", \"REPROVACOES_MAT_4\",\n",
    "    \"NOTA_MAT_1\", \"NOTA_MAT_2\", \"NOTA_MAT_3\", \"NOTA_MAT_4\",\n",
    "    \"INGLES\", \"H_AULA_PRES\", \"TAREFAS_ONLINE\", \"FALTAS\", \n",
    "    \"INGLES_DESC\", # usando todas as colunas\n",
    "    \"CURSOU_MAT1_DESC\", \"CURSOU_MAT2_DESC\", \"CURSOU_MAT3_DESC\", \"CURSOU_MAT4_DESC\",\n",
    "]\n",
    "\n",
    "# Definição da variável-alvo\n",
    "target = [\"PERFIL\"]\n",
    "\n",
    "# Preparação dos argumentos para os métodos da biblioteca ``scikit-learn``\n",
    "X = df_numeros[features]\n",
    "y = df_numeros[target]\n",
    "\n",
    "# Separação dos dados em um conjunto de treino e um conjunto de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c71d24e-8dfd-49c9-bb43-94d8ce0b2f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando os modelos com AUTOML\n",
      "Treinando os modelos com AUTOML\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoML training progress:  98%|██████████████████████████████████▎| 294/300 [04:55<00:06,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando resultados dos modelos com AUTOML\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoML training progress: 100%|███████████████████████████████████| 300/300 [05:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Ranking dos modelos testados: \n",
      "\n",
      "          rank  ensemble_weight               type      cost   duration\n",
      "model_id                                                               \n",
      "5            1             0.24      random_forest  0.193344   8.359419\n",
      "9            2             0.18  gradient_boosting  0.194219   9.839831\n",
      "26           3             0.02                mlp  0.200350  21.292783\n",
      "4            4             0.02  gradient_boosting  0.218524   7.771238\n",
      "21           5             0.02      liblinear_svc  0.219838   2.675278\n",
      "33           6             0.02                mlp  0.220276   7.070588\n",
      "16           7             0.04                lda  0.228596  14.865296\n",
      "23           8             0.04      random_forest  0.237355  22.436863\n",
      "24           9             0.38                lda  0.238012   2.294205\n",
      "25          10             0.04                lda  0.241077   1.628145\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 17 features, but ColumnTransformer is expecting 12 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mRanking dos modelos testados: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(automl\u001b[38;5;241m.\u001b[39mleaderboard())\n\u001b[0;32m---> 43\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mautoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAcurácia: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_score(y_test, y_pred)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/autosklearn/estimators.py:1476\u001b[0m, in \u001b[0;36mAutoSklearnClassifier.predict\u001b[0;34m(self, X, batch_size, n_jobs)\u001b[0m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1465\u001b[0m     \u001b[38;5;124;03m\"\"\"Predict classes for X.\u001b[39;00m\n\u001b[1;32m   1466\u001b[0m \n\u001b[1;32m   1467\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m   1475\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1476\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/autosklearn/estimators.py:798\u001b[0m, in \u001b[0;36mAutoSklearnEstimator.predict\u001b[0;34m(self, X, batch_size, n_jobs)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoml_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/autosklearn/automl.py:2347\u001b[0m, in \u001b[0;36mAutoMLClassifier.predict\u001b[0;34m(self, X, batch_size, n_jobs)\u001b[0m\n\u001b[1;32m   2339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m   2340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2341\u001b[0m     X: SUPPORTED_FEAT_TYPES,\n\u001b[1;32m   2342\u001b[0m     batch_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2343\u001b[0m     n_jobs: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   2344\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m   2345\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 2347\u001b[0m     predicted_probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\n\u001b[1;32m   2349\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mInputValidator\u001b[38;5;241m.\u001b[39mtarget_validator\u001b[38;5;241m.\u001b[39mis_single_column_target():\n\u001b[1;32m   2352\u001b[0m         predicted_indexes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predicted_probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/autosklearn/automl.py:1466\u001b[0m, in \u001b[0;36mAutoML.predict\u001b[0;34m(self, X, batch_size, n_jobs)\u001b[0m\n\u001b[1;32m   1463\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m sklearn\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mNotFittedError:\n\u001b[1;32m   1464\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound no fitted models!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1466\u001b[0m all_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_model_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensemble_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_selected_model_identifiers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_predictions) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1475\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSomething went wrong generating the predictions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe ensemble should consist of the following \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         )\n\u001b[1;32m   1483\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/autosklearn/automl.py:194\u001b[0m, in \u001b[0;36m_model_predict\u001b[0;34m(model, X, task, batch_size, logger)\u001b[0m\n\u001b[1;32m    192\u001b[0m             prediction \u001b[38;5;241m=\u001b[39m predict_func(X_, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 194\u001b[0m             prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# Check that probability values lie between 0 and 1.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m CLASSIFICATION_TASKS:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/autosklearn/pipeline/classification.py:144\u001b[0m, in \u001b[0;36mSimpleClassificationPipeline.predict_proba\u001b[0;34m(self, X, batch_size)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\"predict_proba.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03marray, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_size, \u001b[38;5;28mint\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py:120\u001b[0m, in \u001b[0;36m_IffHasAttrDescriptor.__get__.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m         attrgetter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelegate_names[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])(obj)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# update the docstring of the returned function\u001b[39;00m\n\u001b[1;32m    122\u001b[0m update_wrapper(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py:474\u001b[0m, in \u001b[0;36mPipeline.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    472\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 474\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict_proba(Xt)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/autosklearn/pipeline/components/data_preprocessing/__init__.py:152\u001b[0m, in \u001b[0;36mDataPreprocessorChoice.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: PIPELINE_DATA_DTYPE) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PIPELINE_DATA_DTYPE:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/autosklearn/pipeline/components/data_preprocessing/feature_type.py:226\u001b[0m, in \u001b[0;36mFeatTypeSplit.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumn_transformer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call transform on a Datapreprocessor that has not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myet been fit. Please check the log files for errors \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile trying to fit the model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/compose/_column_transformer.py:556\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m     X_feature_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 556\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     X_feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    559\u001b[0m         np\u001b[38;5;241m.\u001b[39many(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names_in \u001b[38;5;241m!=\u001b[39m X_feature_names)):\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    561\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGiven feature/column names do not match the ones for the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata given during fit.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py:365\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    367\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: X has 17 features, but ColumnTransformer is expecting 12 features as input."
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#import autosklearn.classification\n",
    "import autosklearn.regression\n",
    "\n",
    "\n",
    "# Parâmetros do AutoML\n",
    "total_time = 300  # Tempo total (em segundos)\n",
    "per_model_time = 30  # Tempo máximo por modelo\n",
    "\n",
    "print(\"Criando os modelos com AUTOML\")\n",
    "#cls = autosklearn.classification.AutoSklearnClassifier()\n",
    "reg = autosklearn.regression.AutoSklearnRegressor(\n",
    "    time_left_for_this_task=total_time,\n",
    "    per_run_time_limit=per_model_time,\n",
    "    tmp_folder='/tmp/autosklearn_tmp',\n",
    "    #output_folder='/tmp/autosklearn_out',\n",
    "    disable_evaluator_output=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Iniciando barra de progresso em segundo plano\n",
    "progress_thread_reg = threading.Thread(target=show_progress_bar, args=(total_time,))\n",
    "progress_thread_reg.start()\n",
    "\n",
    "print(\"Treinando os modelos com AUTOML\")\n",
    "#cls.fit(X_train, y_train)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Verificando resultados dos modelos com AUTOML\")\n",
    "#classification_predictions = cls.predict(X_test)\n",
    "regression_predictions = reg.predict(X_test)\n",
    "\n",
    "# Espera barra terminar se for mais rápida\n",
    "progress_thread_reg.join()\n",
    "\n",
    "# Resultados\n",
    "print(\"\\Ranking dos modelos testados: \\n\")\n",
    "print(automl.leaderboard())\n",
    "\n",
    "y_pred = automl.predict(X_test)\n",
    "print(f\"\\Acurácia: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "print(\"\")\n",
    "#print(\"Acurácia usando CLASSIFICACAO com AUTOML: {}%\".format(100*round(accuracy_score(y_test, classification_predictions), 2)))\n",
    "print(\"Acurácia usando REGRESSAO com AUTOML: {}%\".format(100*round(accuracy_score(y_test, regression_predictions), 2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3f9ee-40fb-4c87-8080-e30f00262c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"MLflow AUTOML CLASSIFICACAO x REGRESSAO\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log the hyperparameters\n",
    "    #mlflow.log_params(params)\n",
    "\n",
    "    # Log the loss metric\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y_test, regression_predictions)\n",
    "\n",
    "    # Set a tag that we can use to remind ourselves what this run was for\n",
    "    mlflow.set_tag(\"Training Info\", \"AUTOML CLASSIFICACAO x REGRESSAO\")\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, reg.predict(X_train))\n",
    "\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=reg,\n",
    "        artifact_path=\"curso_model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train,\n",
    "        registered_model_name=\"automl-curso-perfil-alunos\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a25fa0-dad3-4429-aaa2-e55ad610a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model back for predictions as a generic Python Function model\n",
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "#iris_feature_names = datasets.load_iris().feature_names\n",
    "\n",
    "result = pd.DataFrame(X_test, columns=features)\n",
    "result[\"actual_class\"] = y_test\n",
    "result[\"predicted_class\"] = predictions\n",
    "\n",
    "#result[:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
